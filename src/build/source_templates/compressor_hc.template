// Auto-generated: DO NOT EDIT

package net.jpountz.lz4;

import java.nio.ByteBuffer;
import java.util.Arrays;
import static net.jpountz.lz4.LZ4Constants.*;
import static net.jpountz.util.ByteBufferUtils.checkRange;
import static net.jpountz.util.ByteBufferUtils.checkNotReadOnly;
import static net.jpountz.util.Utils.checkRange;
@if{ type == "Unsafe" }
import static net.jpountz.lz4.LZ4UnsafeUtils@{TypeSuffix}.*;
import static net.jpountz.util.UnsafeUtils@{TypeSuffix}.*;
import static net.jpountz.lz4.LZ4Utils.hashHC;

import net.jpountz.util.UnsafeUtils@{TypeSuffix}.Match;
@else{}
import static net.jpountz.lz4.LZ4Utils.*;
import static net.jpountz.util.Utils.*;

import net.jpountz.lz4.LZ4Utils.Match;
@end{}


/**
 * High compression compressor.
 */
final class LZ4HCJava${type}@{TypeSuffix}Compressor extends LZ4Compressor {

  public static final LZ4Compressor INSTANCE = new LZ4HCJava${type}@{TypeSuffix}Compressor();

  private final int maxAttempts;
  final int compressionLevel;
  
  LZ4HCJava${type}@{TypeSuffix}Compressor() { this(DEFAULT_COMPRESSION_LEVEL); }
  LZ4HCJava${type}@{TypeSuffix}Compressor(int compressionLevel) {
    this.maxAttempts = 1<<(compressionLevel-1);
    this.compressionLevel = compressionLevel;
  }

  private class HashTable {
    static final int MASK = MAX_DISTANCE - 1;
    @{OffsetType} nextToUpdate;
    private final @{OffsetType} base;
    private final @{OffsetType}[] hashTable;
    private final short[] chainTable;

    HashTable(@{OffsetType} base) {
      this.base = base;
      nextToUpdate = base;
      hashTable = new @{OffsetType}[HASH_TABLE_SIZE_HC];
      Arrays.fill(hashTable, -1);
      chainTable = new short[MAX_DISTANCE];
    }

    private @{OffsetType} hashPointer(byte[] bytes, @{OffsetType} off) {
      final int v = readInt(bytes, off);
      final int h = hashHC(v);
      return hashTable[h];
    }

    private @{OffsetType} next(@{OffsetType} off) {
      return off - (chainTable[(int)(off & MASK)] & 0xFFFF);
    }

    private void addHash(byte[] bytes, @{OffsetType} off) {
      final int v = readInt(bytes, off);
      final int h = hashHC(v);
      @{OffsetType} delta = off - hashTable[h];
      assert delta > 0 : delta;
      if (delta >= MAX_DISTANCE) {
        delta = MAX_DISTANCE - 1;
      }
      chainTable[(int)(off & MASK)] = (short) delta;
      hashTable[h] = off;
    }

    void insert(@{OffsetType} off, byte[] bytes) {
      for (; nextToUpdate < off; ++nextToUpdate) {
        addHash(bytes, nextToUpdate);
      }
    }

    boolean insertAndFindBestMatch(byte[] buf, @{OffsetType} off, @{OffsetType} matchLimit, Match match) {
      match.start = off;
      match.len = 0;
      @{OffsetType} delta = 0;
      int repl = 0;

      insert(off, buf);

      @{OffsetType} ref = hashPointer(buf, off);

      if (ref >= off - 4 && ref <= off && ref >= base) { // potential repetition
        if (readIntEquals(buf, ref, off)) { // confirmed
          delta = off - ref;
          repl = match.len = MIN_MATCH + commonBytes(buf, ref + MIN_MATCH, off + MIN_MATCH, matchLimit);
          match.ref = ref;
        }
        ref = next(ref);
      }

      for (int i = 0; i < maxAttempts; ++i) {
        if (ref < Math.max(base, off - MAX_DISTANCE + 1) || ref > off) {
          break;
        }
        if (readByte(buf, ref + match.len) == readByte(buf, off + match.len) && readIntEquals(buf, ref, off)) {
          final int matchLen = MIN_MATCH + commonBytes(buf, ref + MIN_MATCH, off + MIN_MATCH, matchLimit);
          if (matchLen > match.len) {
            match.ref = ref;
            match.len = matchLen;
          }
        }
        ref = next(ref);
      }

      if (repl != 0) {
        @{OffsetType} ptr = off;
        final @{OffsetType} end = off + repl - (MIN_MATCH - 1);
        while (ptr < end - delta) {
          chainTable[(int)(ptr & MASK)] = (short) delta; // pre load
          ++ptr;
        }
        do {
          chainTable[(int)(ptr & MASK)] = (short) delta;
          hashTable[hashHC(readInt(buf, ptr))] = ptr;
          ++ptr;
        } while (ptr < end);
        nextToUpdate = end;
      }

      return match.len != 0;
    }

    boolean insertAndFindWiderMatch(byte[] buf, @{OffsetType} off, @{OffsetType} startLimit, @{OffsetType} matchLimit, int minLen, Match match) {
      match.len = minLen;

      insert(off, buf);

      final @{OffsetType} delta = off - startLimit;
      @{OffsetType} ref = hashPointer(buf, off);
      for (int i = 0; i < maxAttempts; ++i) {
        if (ref < Math.max(base, off - MAX_DISTANCE + 1) || ref > off) {
          break;
        }
        if (readByte(buf, ref - delta + match.len) == readByte(buf, startLimit + match.len)
            && readIntEquals(buf, ref, off)) {
          final int matchLenForward = MIN_MATCH + commonBytes(buf, ref + MIN_MATCH, off + MIN_MATCH, matchLimit);
          final int matchLenBackward = commonBytesBackward(buf, ref, off, base, startLimit);
          final int matchLen = matchLenBackward + matchLenForward;
          if (matchLen > match.len) {
            match.len = matchLen;
            match.ref = ref - matchLenBackward;
            match.start = off - matchLenBackward;
          }
        }
        ref = next(ref);
      }

      return match.len > minLen;
    }

  }

  private int compressUnchecked(
      byte[] src, @{OffsetType} srcOff, int srcLen,
      byte[] dest, @{OffsetType} destOff, int maxDestLen) {

    final @{OffsetType} srcEnd = srcOff + srcLen;
    final @{OffsetType} destEnd = destOff + maxDestLen;
    final @{OffsetType} mfLimit = srcEnd - MF_LIMIT;
    final @{OffsetType} matchLimit = srcEnd - LAST_LITERALS;

    @{OffsetType} sOff = srcOff;
    @{OffsetType} dOff = destOff;
    @{OffsetType} anchor = sOff++;

    final HashTable ht = new HashTable(srcOff);
    final Match match0 = new Match();
    final Match match1 = new Match();
    final Match match2 = new Match();
    final Match match3 = new Match();

    main:
    while (sOff < mfLimit) {
      if (!ht.insertAndFindBestMatch(src, sOff, matchLimit, match1)) {
        ++sOff;
        continue;
      }

      // saved, in case we would skip too much
      copyTo(match1, match0);

      search2:
      while (true) {
        assert match1.start >= anchor;
        if (match1.end() >= mfLimit
            || !ht.insertAndFindWiderMatch(src, match1.end() - 2, match1.start + 1, matchLimit, match1.len, match2)) {
          // no better match
          dOff = encodeSequence(src, anchor, match1.start, match1.ref, match1.len, dest, dOff, destEnd);
          anchor = sOff = match1.end();
          continue main;
        }

        if (match0.start < match1.start) {
          if (match2.start < match1.start + match0.len) { // empirical
            copyTo(match0, match1);
          }
        }
        assert match2.start > match1.start;

        if (match2.start - match1.start < 3) { // First Match too small : removed
          copyTo(match2, match1);
          continue search2;
        }

        search3:
        while (true) {
          if (match2.start - match1.start < OPTIMAL_ML) {
            int newMatchLen = match1.len;
            if (newMatchLen > OPTIMAL_ML) {
              newMatchLen = OPTIMAL_ML;
            }
            if (match1.start + newMatchLen > match2.end() - MIN_MATCH) {
              newMatchLen = (int) (match2.start - match1.start + match2.len - MIN_MATCH);
            }
            final int correction = newMatchLen - (int) (match2.start - match1.start);
            if (correction > 0) {
              match2.fix(correction);
            }
          }

          if (match2.start + match2.len >= mfLimit
              || !ht.insertAndFindWiderMatch(src, match2.end() - 3, match2.start, matchLimit, match2.len, match3)) {
            // no better match -> 2 sequences to encode
            if (match2.start < match1.end()) {
              match1.len = (int) (match2.start - match1.start);
            }
            // encode seq 1
            dOff = encodeSequence(src, anchor, match1.start, match1.ref, match1.len, dest, dOff, destEnd);
            anchor = sOff = match1.end();
            // encode seq 2
            dOff = encodeSequence(src, anchor, match2.start, match2.ref, match2.len, dest, dOff, destEnd);
            anchor = sOff = match2.end();
            continue main;
          }

          if (match3.start < match1.end() + 3) { // Not enough space for match 2 : remove it
            if (match3.start >= match1.end()) { // // can write Seq1 immediately ==> Seq2 is removed, so Seq3 becomes Seq1
              if (match2.start < match1.end()) {
                final int correction = (int) (match1.end() - match2.start);
                match2.fix(correction);
                if (match2.len < MIN_MATCH) {
                  copyTo(match3, match2);
                }
              }

              dOff = encodeSequence(src, anchor, match1.start, match1.ref, match1.len, dest, dOff, destEnd);
              anchor = sOff = match1.end();

              copyTo(match3, match1);
              copyTo(match2, match0);

              continue search2;
            }

            copyTo(match3, match2);
            continue search3;
          }

          // OK, now we have 3 ascending matches; let's write at least the first one
          if (match2.start < match1.end()) {
            if (match2.start - match1.start < ML_MASK) {
              if (match1.len > OPTIMAL_ML) {
                match1.len = OPTIMAL_ML;
              }
              if (match1.end() > match2.end() - MIN_MATCH) {
                match1.len = (int) (match2.end() - match1.start - MIN_MATCH);
              }
              final int correction = (int) (match1.end() - match2.start);
              match2.fix(correction);
            } else {
              match1.len = (int) (match2.start - match1.start);
            }
          }

          dOff = encodeSequence(src, anchor, match1.start, match1.ref, match1.len, dest, dOff, destEnd);
          anchor = sOff = match1.end();

          copyTo(match2, match1);
          copyTo(match3, match2);

          continue search3;
        }

      }

    }

    dOff = lastLiterals(src, anchor, (int) (srcEnd - anchor), dest, dOff, destEnd);
    return (int) (dOff - destOff);
  }
  
@if{ type == "Safe" }
  @Override
  public int compress(
      byte[] src, int srcOff, int srcLen,
      byte[] dest, int destOff, int maxDestLen) {

    checkRange(src, srcOff, srcLen);
    checkRange(dest, destOff, maxDestLen);

    return compressUnchecked(src, srcOff, srcLen, dest, destOff, maxDestLen);
  }

  @Override
  public int compress(ByteBuffer src, int srcOff, int srcLen, ByteBuffer dst, int dstOff, int dstLen) {
    // The process is complex enough that copying the arrays gives better performance than
    // operating on the buffers directly.
    checkRange(src, srcOff, srcLen);
    checkRange(dst, dstOff, dstLen);
    checkNotReadOnly(dst);

    byte[] srcArray;
    if (src.hasArray()) {
      srcArray = src.array();
      srcOff += src.arrayOffset();
    } else {
      srcArray = new byte[srcLen];
      src = src.duplicate();
      src.limit(srcLen + srcOff).position(srcOff);
      src.get(srcArray);
      srcOff = 0;
    }
    byte[] dstArray;
    int dstArrayOff = dstOff;
    if (dst.hasArray()) {
      dstArray = dst.array();
      dstArrayOff += dst.arrayOffset();
    } else {
      dstArray = new byte[dstLen];
      dstArrayOff = 0;
    }
    int len = compressUnchecked(srcArray, srcOff, srcLen, dstArray, dstArrayOff, dstLen);
    if (!dst.hasArray()) {
      dst = dst.duplicate();
      dst.limit(dstOff + dstLen).position(dstOff);
      dst.put(dstArray);
    }
    return len;
  }
@else{}
@include{"adapters.template"; Method = "compress"; WithSrcLen = true }
@end{}  

}
